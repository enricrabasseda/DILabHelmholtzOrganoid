{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organoseg dataset creation\n",
    "\n",
    "This notebook gives a schema and the total steps to generate patches for the dataset used in Organoseg paper. This dataset contains colon organoid pictures, but is designed for semantic segmentation tasks. There is a total of 64 images, but here we augment it by creating patches.\n",
    "\n",
    "## Initialization\n",
    "\n",
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from patchify import patchify\n",
    "import tifffile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the main directory and the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory as the main directory\n",
    "os.chdir(\"/home/ubuntu/\")\n",
    "# Data directory\n",
    "data_dir = \"/home/ubuntu/data/colon_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the lists containing all the information:\n",
    "* Directory list: contains the paths to all images.\n",
    "* Masks list: contains the path to the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_source_list = []\n",
    "masks_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original semantic segmentation dataset creation\n",
    "In this part we read the images that are in .tif format and get the path and their masks path.\n",
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images_dir = os.path.join(data_dir, \"original\", \"colon_images\")\n",
    "original_masks_dir = os.path.join(data_dir, \"original\", \"colon_masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image conversion and saving information\n",
    "Get all images in the directory in `.tif` format and convert them to `.png`. Save the paths to the images and their corresponding masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image directories.\n",
    "list_original_images_name = os.listdir(original_images_dir)\n",
    "\n",
    "# Save all images\n",
    "for i in range(len(list_original_images_name)):\n",
    "    # Get image as array\n",
    "    tif_array = tifffile.imread(os.path.join(original_images_dir, list_original_images_name[i]))\n",
    "    # Get image source name\n",
    "    img_name, _ = os.path.splitext(list_original_images_name[i])\n",
    "\n",
    "    # Save image in .png format\n",
    "    cv2.imwrite(os.path.join(original_images_dir, img_name  + \".png\"), tif_array)\n",
    "    \n",
    "    # Save image path\n",
    "    img_source_list.append(os.path.join(original_images_dir, img_name  + \".png\"))\n",
    "    # Save image mask\n",
    "    masks_list.append(os.path.join(original_masks_dir, \"slice_\" + img_name  + \"_bw.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions of original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset contains 64 images of size 648 x 864 .\n"
     ]
    }
   ],
   "source": [
    "H, W, _ = tif_array.shape\n",
    "print(\"This dataset contains\", len(img_source_list), \"images of size\", H, \"x\", W, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of semantic segmentation augmented dataset\n",
    "In this part we get 4 patches per image and get an augmented dataset from the previous original one.\n",
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images_dir = os.path.join(data_dir, \"augmented\", \"colon_images\")\n",
    "augmented_masks_dir = os.path.join(data_dir, \"augmented\", \"colon_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image_path_list = []\n",
    "augmented_mask_path_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patches creation and saving information\n",
    "\n",
    "Get 4 patches per image and adjust the masks respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 patches for image of size 324 x 432\n"
     ]
    }
   ],
   "source": [
    "# Calculate the dimensions of patches in each dimension\n",
    "h_patches = H // 2\n",
    "w_patches = W // 2\n",
    "\n",
    "# Desired patch size\n",
    "patch_size = (h_patches, w_patches, 3)\n",
    "\n",
    "# Adjust the step size to ensure non-overlapping patches\n",
    "step_size_h = H // 2\n",
    "step_size_w = W // 2\n",
    "\n",
    "# Create patches\n",
    "patches = patchify(tif_array, patch_size, step=(step_size_h, step_size_w, 1))\n",
    "\n",
    "print(patches.shape[0]*patches.shape[1], \"patches for image of size\", \n",
    "      patches.shape[3], \"x\", patches.shape[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the paths to the new patched images and masks in the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name = os.listdir(original_images_dir)\n",
    "\n",
    "for i in range(len(images_name)):\n",
    "    # Get image as array\n",
    "    image_array = cv2.imread(os.path.join(original_images_dir, images_name[i]))\n",
    "    # Get image source name\n",
    "    img_name, _ = os.path.splitext(images_name[i])\n",
    "    # Get mask as array\n",
    "    mask_array = cv2.imread(os.path.join(original_masks_dir, \"slice_\" + img_name + \"_bw.png\"))\n",
    "\n",
    "    # Get patches for the image\n",
    "    image_patches = patchify(image_array, patch_size, step=(step_size_h, step_size_w, 1))\n",
    "    # Get patches for the mask\n",
    "    mask_patches = patchify(mask_array, patch_size, step=(step_size_h, step_size_w, 1))\n",
    "\n",
    "    # Run through patches\n",
    "    for r in range(image_patches.shape[0]):\n",
    "        for c in range(image_patches.shape[1]):\n",
    "            # Save image in .png format\n",
    "            cv2.imwrite(os.path.join(augmented_images_dir, img_name + \"_\" + str(r) + str(c) + \".png\"), image_patches[r,c,0,:,:])\n",
    "            # Save the path of image\n",
    "            img_source_list.append(os.path.join(augmented_images_dir, img_name + \"_\" + str(r) + str(c) + \".png\"))\n",
    "            augmented_image_path_list.append(os.path.join(augmented_images_dir, img_name + \"_\" + str(r) + str(c) + \".png\"))\n",
    "            # Save mask in .png format\n",
    "            cv2.imwrite(os.path.join(augmented_masks_dir, \"slice_\" + img_name + \"_\" + str(r) + str(c) + \"_bw.png\"), mask_patches[r,c,0,:,:])\n",
    "            # Save the path of mask\n",
    "            masks_list.append(os.path.join(augmented_masks_dir, \"slice_\" + img_name + \"_\" + str(r) + str(c) + \"_bw.png\"))\n",
    "            augmented_mask_path_list.append(os.path.join(augmented_masks_dir, \"slice_\" + img_name + \"_\" + str(r) + str(c) + \"_bw.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions of patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset contains 256 images of size 324 x 432 .\n"
     ]
    }
   ],
   "source": [
    "print(\"This dataset contains\", len(augmented_image_path_list), \"images of size\", patch_size[0], \"x\", patch_size[1], \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL: Semantic segmentation dataset creation\n",
    "\n",
    "Now we can create the file needed to later load the information as a dataset. To do it, we create a pandas dataframe that we save later as .json format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(img_source_list, masks_list)),\n",
    "               columns =['img', 'masks'])\n",
    "\n",
    "df.to_json(data_dir + \"/metadata_semantic_segmentation.json\", orient = \"records\", lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "TOTAL DATASET\n",
      "Total number of images: 320\n",
      "Total number of masks: 320\n",
      "------------------\n",
      "ORIGINAL DATASET\n",
      "Total number of images: 64\n",
      "Total number of masks: 64\n",
      "------------------\n",
      "AUGMENTED DATASET\n",
      "Total number of images: 256\n",
      "Total number of masks: 256\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------\")\n",
    "print(\"TOTAL DATASET\")\n",
    "print(\"Total number of images:\", len(img_source_list))\n",
    "print(\"Total number of masks:\", len(masks_list))\n",
    "print(\"------------------\")\n",
    "print(\"ORIGINAL DATASET\")\n",
    "print(\"Total number of images:\", 64)\n",
    "print(\"Total number of masks:\", 64)\n",
    "print(\"------------------\")\n",
    "print(\"AUGMENTED DATASET\")\n",
    "print(\"Total number of images:\", len(augmented_image_path_list))\n",
    "print(\"Total number of masks:\", len(augmented_mask_path_list))\n",
    "print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance segmentation augmented dataset\n",
    "\n",
    "Here we create a dataset containing one mask for every organoid in the original images. The masks are extracted one by one from the original masks using connected components analysis.\n",
    "\n",
    "### Image loading\n",
    "\n",
    "First we get the paths to the images and masks, and also a list containing all relative paths to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_seg_images_dir = os.path.join(data_dir, \"augmented\", \"colon_images\")\n",
    "augmented_seg_masks_dir = os.path.join(data_dir, \"augmented\", \"colon_masks\")\n",
    "augmented_inst_masks_dir = os.path.join(data_dir, \"augmented\", \"colon_instance_masks\")\n",
    "\n",
    "# Relative path to images\n",
    "list_augmented_seg_images_name = os.listdir(augmented_seg_images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty lists that will contain all `metadata.json` information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = []\n",
    "mask_path_list = []\n",
    "box_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create now the instance segmentation masks for all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_augmented_seg_images_name)):\n",
    "    # Load the image and semantic segmentation mask\n",
    "    img_name, _ = os.path.splitext(list_augmented_seg_images_name[i])\n",
    "    img_path = augmented_seg_images_dir + \"/\" + list_augmented_seg_images_name[i]\n",
    "    mask_path = augmented_seg_masks_dir + \"/\" + \"slice_\" + img_name + \"_bw.png\"\n",
    "    # Assuming 'mask' is your binary mask, load it\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Perform connected components analysis\n",
    "    output = cv2.connectedComponentsWithStats(mask, connectivity=8, ltype=cv2.CV_32S)\n",
    "    # Here we save the relevant information about the connected components\n",
    "    (numLabels, labels, stats, centroids) = output\n",
    "\n",
    "    # Save the masks in the corresponding file and all relevant information: framing box and paths; to be saved later in metadata.json file.\n",
    "    for label in range(1,stats.shape[0]):\n",
    "        if label < 10:\n",
    "            num = \"0\" + str(label)\n",
    "        else:\n",
    "            num = str(label)\n",
    "        # Get mask according to the label\n",
    "        mask_for_label = (labels == label)*255\n",
    "        # Save it\n",
    "        mask_path = augmented_inst_masks_dir + \"/\" + \"slice_\" + img_name + \"_\" + num + \"_bw.png\"\n",
    "        cv2.imwrite(mask_path, mask_for_label)\n",
    "\n",
    "        # Get box corresponding to mask\n",
    "        box_mask = [stats[label,0], stats[label,1], stats[label,0] + stats[label,2], stats[label,1] + stats[label,3]]\n",
    "\n",
    "        # Save information in the lists\n",
    "        image_path_list.append(img_path)\n",
    "        mask_path_list.append(mask_path)\n",
    "        box_list.append(box_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 256 images with a total number of 5706 organoids.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(list_augmented_seg_images_name), \"images with a total number of\", len(mask_path_list), \"organoids.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metadata\n",
    "\n",
    "Here we save all the information in a `metadata.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(image_path_list, box_list, mask_path_list)),\n",
    "               columns =['img', 'box', 'mask'])\n",
    "\n",
    "df.to_json(data_dir + \"/metadata_instance_segmentation.json\", orient = \"records\", lines = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
